{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "from contextlib import suppress\n",
    "\n",
    "from effdet import create_model, create_evaluator, create_dataset, create_loader\n",
    "from effdet.data import resolve_input_config\n",
    "from timm.utils import AverageMeter, setup_default_logging\n",
    "from timm.models.layers import set_layer_config\n",
    "\n",
    "has_apex = False\n",
    "try:\n",
    "    from apex import amp\n",
    "    has_apex = True\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "has_native_amp = False\n",
    "try:\n",
    "    if getattr(torch.cuda.amp, 'autocast') is not None:\n",
    "        has_native_amp = True\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def add_bool_arg(parser, name, default=False, help=''):  # FIXME move to utils\n",
    "    dest_name = name.replace('-', '_')\n",
    "    group = parser.add_mutually_exclusive_group(required=False)\n",
    "    group.add_argument('--' + name, dest=dest_name, action='store_true', help=help)\n",
    "    group.add_argument('--no-' + name, dest=dest_name, action='store_false', help=help)\n",
    "    parser.set_defaults(**{dest_name: default})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--results'], dest='results', nargs=None, const=None, default='', type=<class 'str'>, choices=None, help='JSON filename for evaluation results', metavar='FILENAME')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch ImageNet Validation')\n",
    "parser.add_argument('root', metavar='DIR',\n",
    "                    help='path to dataset root')\n",
    "parser.add_argument('--dataset', default='coco', type=str, metavar='DATASET',\n",
    "                    help='Name of dataset (default: \"coco\"')\n",
    "parser.add_argument('--split', default='val',\n",
    "                    help='validation split')\n",
    "parser.add_argument('--model', '-m', metavar='MODEL', default='tf_efficientdet_d1',\n",
    "                    help='model architecture (default: tf_efficientdet_d1)')\n",
    "add_bool_arg(parser, 'redundant-bias', default=None,\n",
    "                    help='override model config for redundant bias layers')\n",
    "add_bool_arg(parser, 'soft-nms', default=None, help='override model config for soft-nms')\n",
    "parser.add_argument('--num-classes', type=int, default=None, metavar='N',\n",
    "                    help='Override num_classes in model config if set. For fine-tuning from pretrained.')\n",
    "parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 4)')\n",
    "parser.add_argument('-b', '--batch-size', default=128, type=int,\n",
    "                    metavar='N', help='mini-batch size (default: 128)')\n",
    "parser.add_argument('--img-size', default=None, type=int,\n",
    "                    metavar='N', help='Input image dimension, uses model default if empty')\n",
    "parser.add_argument('--mean', type=float, nargs='+', default=None, metavar='MEAN',\n",
    "                    help='Override mean pixel value of dataset')\n",
    "parser.add_argument('--std', type=float,  nargs='+', default=None, metavar='STD',\n",
    "                    help='Override std deviation of of dataset')\n",
    "parser.add_argument('--interpolation', default='bilinear', type=str, metavar='NAME',\n",
    "                    help='Image resize interpolation type (overrides model)')\n",
    "parser.add_argument('--fill-color', default=None, type=str, metavar='NAME',\n",
    "                    help='Image augmentation fill (background) color (\"mean\" or int)')\n",
    "parser.add_argument('--log-freq', default=10, type=int,\n",
    "                    metavar='N', help='batch logging frequency (default: 10)')\n",
    "parser.add_argument('--checkpoint', default='', type=str, metavar='PATH',\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('--pretrained', dest='pretrained', action='store_true',\n",
    "                    help='use pre-trained model')\n",
    "parser.add_argument('--num-gpu', type=int, default=1,\n",
    "                    help='Number of GPUS to use')\n",
    "parser.add_argument('--no-prefetcher', action='store_true', default=False,\n",
    "                    help='disable fast prefetcher')\n",
    "parser.add_argument('--pin-mem', action='store_true', default=False,\n",
    "                    help='Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.')\n",
    "parser.add_argument('--use-ema', dest='use_ema', action='store_true',\n",
    "                    help='use ema version of weights if present')\n",
    "parser.add_argument('--amp', action='store_true', default=False,\n",
    "                    help='Use AMP mixed precision. Defaults to Apex, fallback to native Torch AMP.')\n",
    "parser.add_argument('--apex-amp', action='store_true', default=False,\n",
    "                    help='Use NVIDIA Apex AMP mixed precision')\n",
    "parser.add_argument('--native-amp', action='store_true', default=False,\n",
    "                    help='Use Native Torch AMP mixed precision')\n",
    "parser.add_argument('--torchscript', dest='torchscript', action='store_true',\n",
    "                    help='convert model torchscript for inference')\n",
    "parser.add_argument('--results', default='', type=str, metavar='FILENAME',\n",
    "                    help='JSON filename for evaluation results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(args):\n",
    "    setup_default_logging()\n",
    "\n",
    "    if args.amp:\n",
    "        if has_native_amp:\n",
    "            args.native_amp = True\n",
    "        elif has_apex:\n",
    "            args.apex_amp = True\n",
    "    assert not args.apex_amp or not args.native_amp, \"Only one AMP mode should be set.\"\n",
    "    args.pretrained = args.pretrained or not args.checkpoint  # might as well try to validate something\n",
    "    args.prefetcher = not args.no_prefetcher\n",
    "\n",
    "    # create model\n",
    "    with set_layer_config(scriptable=args.torchscript):\n",
    "        extra_args = {}\n",
    "        if args.img_size is not None:\n",
    "            extra_args = dict(image_size=(args.img_size, args.img_size))\n",
    "        bench = create_model(\n",
    "            args.model,\n",
    "            bench_task='predict',\n",
    "            num_classes=args.num_classes,\n",
    "            pretrained=args.pretrained,\n",
    "            redundant_bias=args.redundant_bias,\n",
    "            soft_nms=args.soft_nms,\n",
    "            checkpoint_path=args.checkpoint,\n",
    "            checkpoint_ema=args.use_ema,\n",
    "            **extra_args,\n",
    "        )\n",
    "    model_config = bench.config\n",
    "\n",
    "    param_count = sum([m.numel() for m in bench.parameters()])\n",
    "    print('Model %s created, param count: %d' % (args.model, param_count))\n",
    "\n",
    "    bench = bench.cuda()\n",
    "\n",
    "    amp_autocast = suppress\n",
    "    if args.apex_amp:\n",
    "        bench = amp.initialize(bench, opt_level='O1')\n",
    "        print('Using NVIDIA APEX AMP. Validating in mixed precision.')\n",
    "    elif args.native_amp:\n",
    "        amp_autocast = torch.cuda.amp.autocast\n",
    "        print('Using native Torch AMP. Validating in mixed precision.')\n",
    "    else:\n",
    "        print('AMP not enabled. Validating in float32.')\n",
    "\n",
    "    if args.num_gpu > 1:\n",
    "        bench = torch.nn.DataParallel(bench, device_ids=list(range(args.num_gpu)))\n",
    "\n",
    "    dataset = create_dataset(args.dataset, args.root, args.split)\n",
    "    input_config = resolve_input_config(args, model_config)\n",
    "    loader = create_loader(\n",
    "        dataset,\n",
    "        input_size=input_config['input_size'],\n",
    "        batch_size=args.batch_size,\n",
    "        use_prefetcher=args.prefetcher,\n",
    "        interpolation=input_config['interpolation'],\n",
    "        fill_color=input_config['fill_color'],\n",
    "        mean=input_config['mean'],\n",
    "        std=input_config['std'],\n",
    "        num_workers=args.workers,\n",
    "        pin_mem=args.pin_mem)\n",
    "\n",
    "    evaluator = create_evaluator(args.dataset, dataset, pred_yxyx=False)\n",
    "    bench.eval()\n",
    "    batch_time = AverageMeter()\n",
    "    end = time.time()\n",
    "    last_idx = len(loader) - 1\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(loader):\n",
    "            with amp_autocast():\n",
    "                output = bench(input, img_info=target)\n",
    "            evaluator.add_predictions(output, target)\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % args.log_freq == 0 or i == last_idx:\n",
    "                print(\n",
    "                    'Test: [{0:>4d}/{1}]  '\n",
    "                    'Time: {batch_time.val:.3f}s ({batch_time.avg:.3f}s, {rate_avg:>7.2f}/s)  '\n",
    "                    .format(\n",
    "                        i, len(loader), batch_time=batch_time,\n",
    "                        rate_avg=input.size(0) / batch_time.avg)\n",
    "                )\n",
    "\n",
    "    mean_ap = 0.\n",
    "    if dataset.parser.has_labels:\n",
    "        mean_ap = evaluator.evaluate(output_result_file=args.results)\n",
    "    else:\n",
    "        evaluator.save(args.results)\n",
    "\n",
    "    return mean_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model tf_efficientdet_d0 created, param count: 3880067\n",
      "AMP not enabled. Validating in float32.\n",
      "loading annotations into memory...\n",
      "Done (t=0.33s)\n",
      "creating index...\n",
      "index created!\n",
      "Test: [   0/40]  Time: 13.798s (13.798s,    9.28/s)  \n",
      "Test: [  10/40]  Time: 0.869s (2.003s,   63.92/s)  \n",
      "Test: [  20/40]  Time: 0.857s (1.437s,   89.06/s)  \n",
      "Test: [  30/40]  Time: 0.796s (1.245s,  102.84/s)  \n",
      "Test: [  39/40]  Time: 0.973s (1.158s,    6.91/s)  \n",
      "Loading and preparing results...\n",
      "DONE (t=3.53s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=46.31s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=10.75s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.525\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.359\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.132\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.399\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.537\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.293\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.448\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.473\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.558\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.341521214794073"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args_str = 'data --model tf_efficientdet_d0 --num-gpu 4'\n",
    "args,_ = parser.parse_known_args(args=args_str.split())\n",
    "\n",
    "validate(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image 이름에 index 부여해서 어떻게 분할된 이미지인지 구분\n",
    "# 동일모델 복사 후 모델 내에서 index와 함께 결과 전송"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "from IPython.display import display\n",
    "\n",
    "n_tile = 2 # partitioned width or height\n",
    "path = 'data/val2017'\n",
    "save_dir = 'data/cropped/val2017'\n",
    "file_list = os.listdir(path)\n",
    "for img_name in file_list:\n",
    "  img = Image.open(path+'/'+img_name)\n",
    "  #display(img)\n",
    "  width, height = img.size\n",
    "  sub_width = int(4*width/(3*n_tile+1))\n",
    "  sub_height = int(4*height/(3*n_tile+1))\n",
    "  #print('original : ',width,height)\n",
    "  #print('sub : ',sub_width,sub_height)\n",
    "  ind = 0\n",
    "  for h in range(n_tile):\n",
    "    for w in range(n_tile):\n",
    "      #print(w*(width-sub_width),h*(height-sub_height)) # 시작점\n",
    "      #print(sub_width+w*(width-sub_width),sub_height+h*(height-sub_height)) # 끝점\n",
    "      area = (w*(width-sub_width),h*(height-sub_height),sub_width+w*(width-sub_width),sub_height+h*(height-sub_height))\n",
    "      sub_img = img.crop(area)\n",
    "      #display(sub_img)\n",
    "      save_file = save_dir+'/'+img_name[:-4]+\"_\"+str(ind)+img_name[-4:]\n",
    "      ind+=1\n",
    "      sub_img.save(save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1609c5d6daf415add5fd1f90da23d5406f9079b60a4e5640100862a3157a35d6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('t': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
