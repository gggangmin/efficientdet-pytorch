{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 작동 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "from contextlib import suppress\n",
    "\n",
    "from effdet import create_model, create_evaluator, create_dataset, create_loader\n",
    "from effdet.data import resolve_input_config\n",
    "from timm.utils import AverageMeter, setup_default_logging\n",
    "from timm.models.layers import set_layer_config\n",
    "\n",
    "from matplotlib import pyplot as plt # for visualization\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import warnings\n",
    "from PIL import Image\n",
    "from torchvision.ops.boxes import batched_nms\n",
    "\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "has_apex = False\n",
    "try:\n",
    "    from apex import amp\n",
    "    has_apex = True\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "has_native_amp = False\n",
    "try:\n",
    "    if getattr(torch.cuda.amp, 'autocast') is not None:\n",
    "        has_native_amp = True\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def add_bool_arg(parser, name, default=False, help=''):  # FIXME move to utils\n",
    "    dest_name = name.replace('-', '_')\n",
    "    group = parser.add_mutually_exclusive_group(required=False)\n",
    "    group.add_argument('--' + name, dest=dest_name, action='store_true', help=help)\n",
    "    group.add_argument('--no-' + name, dest=dest_name, action='store_false', help=help)\n",
    "    parser.set_defaults(**{dest_name: default})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--results'], dest='results', nargs=None, const=None, default='', type=<class 'str'>, choices=None, help='JSON filename for evaluation results', metavar='FILENAME')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch ImageNet Validation')\n",
    "parser.add_argument('root', metavar='DIR',\n",
    "                    help='path to dataset root') # 디폴트 데이터셋 파싱\n",
    "parser.add_argument('--dataset', default='coco', type=str, metavar='DATASET',\n",
    "                    help='Name of dataset (default: \"coco\"') \n",
    "parser.add_argument('--split', default='val',\n",
    "                    help='validation split')\n",
    "parser.add_argument('--model', '-m', metavar='MODEL', default='tf_efficientdet_d1',\n",
    "                    help='model architecture (default: tf_efficientdet_d1)')\n",
    "add_bool_arg(parser, 'redundant-bias', default=None,\n",
    "                    help='override model config for redundant bias layers')\n",
    "add_bool_arg(parser, 'soft-nms', default=None, help='override model config for soft-nms')\n",
    "parser.add_argument('--num-classes', type=int, default=None, metavar='N',\n",
    "                    help='Override num_classes in model config if set. For fine-tuning from pretrained.')\n",
    "parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 4)')\n",
    "parser.add_argument('-b', '--batch-size', default=128, type=int,\n",
    "                    metavar='N', help='mini-batch size (default: 128)')\n",
    "parser.add_argument('--img-size', default=None, type=int,\n",
    "                    metavar='N', help='Input image dimension, uses model default if empty')\n",
    "parser.add_argument('--mean', type=float, nargs='+', default=None, metavar='MEAN',\n",
    "                    help='Override mean pixel value of dataset')\n",
    "parser.add_argument('--std', type=float,  nargs='+', default=None, metavar='STD',\n",
    "                    help='Override std deviation of of dataset')\n",
    "parser.add_argument('--interpolation', default='bilinear', type=str, metavar='NAME',\n",
    "                    help='Image resize interpolation type (overrides model)')\n",
    "parser.add_argument('--fill-color', default=None, type=str, metavar='NAME',\n",
    "                    help='Image augmentation fill (background) color (\"mean\" or int)')\n",
    "parser.add_argument('--log-freq', default=10, type=int,\n",
    "                    metavar='N', help='batch logging frequency (default: 10)')\n",
    "parser.add_argument('--checkpoint', default='', type=str, metavar='PATH',\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('--pretrained', dest='pretrained', action='store_true',\n",
    "                    help='use pre-trained model')\n",
    "parser.add_argument('--num-gpu', type=int, default=1,\n",
    "                    help='Number of GPUS to use')\n",
    "parser.add_argument('--no-prefetcher', action='store_true', default=False,\n",
    "                    help='disable fast prefetcher')\n",
    "parser.add_argument('--pin-mem', action='store_true', default=False,\n",
    "                    help='Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.')\n",
    "parser.add_argument('--use-ema', dest='use_ema', action='store_true',\n",
    "                    help='use ema version of weights if present')\n",
    "parser.add_argument('--amp', action='store_true', default=False,\n",
    "                    help='Use AMP mixed precision. Defaults to Apex, fallback to native Torch AMP.')\n",
    "parser.add_argument('--apex-amp', action='store_true', default=False,\n",
    "                    help='Use NVIDIA Apex AMP mixed precision')\n",
    "parser.add_argument('--native-amp', action='store_true', default=False,\n",
    "                    help='Use Native Torch AMP mixed precision')\n",
    "parser.add_argument('--torchscript', dest='torchscript', action='store_true',\n",
    "                    help='convert model torchscript for inference')\n",
    "parser.add_argument('--results', default='', type=str, metavar='FILENAME',\n",
    "                    help='JSON filename for evaluation results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization(output,file_number:int):\n",
    "  # ############################\n",
    "  # visualization aggregation\n",
    "  # ############################\n",
    "  '''\n",
    "  file_number : must be cpu integer\n",
    "  '''\n",
    "  \n",
    "  fig, ax = plt.subplots()\n",
    "\n",
    "  for bi in range(len(output)): # num of box\n",
    "    box = output[bi]\n",
    "    b = np.array(box.cpu())\n",
    "    ax.add_patch(\n",
    "      patches.Rectangle(\n",
    "        # 좌표변경 xyxy -> xywh\n",
    "        (b[0],b[1]),b[2]-b[0] ,b[3]-b[1] , edgecolor = 'red', fill=False)\n",
    "        \n",
    "      \n",
    "    )\n",
    "    '''\n",
    "    centerx = b[0]+ (b[2]-b[0])/2 \n",
    "    centery = b[1]+ (b[3]-b[1])/2\n",
    "    ax.text(centerx,centery,b[5])\n",
    "    '''\n",
    "  file_number = str(file_number)\n",
    "  #file_name = '0'*(12-len(file_number))+file_number\n",
    "  img = Image.open('data_air/images/'+file_number+'.jpg')\n",
    "  ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(args):\n",
    "    setup_default_logging()\n",
    "\n",
    "    if args.amp:\n",
    "        if has_native_amp:\n",
    "            args.native_amp = True\n",
    "        elif has_apex:\n",
    "            args.apex_amp = True\n",
    "    assert not args.apex_amp or not args.native_amp, \"Only one AMP mode should be set.\"\n",
    "    args.pretrained = args.pretrained or not args.checkpoint  # might as well try to validate something\n",
    "    args.prefetcher = not args.no_prefetcher\n",
    "\n",
    "    # create model\n",
    "    with set_layer_config(scriptable=args.torchscript):\n",
    "        extra_args = {}\n",
    "        if args.img_size is not None:\n",
    "            extra_args = dict(image_size=(args.img_size, args.img_size))\n",
    "\n",
    "        #extra_args = dict(image_size = (365,292), max_detection_points = 2000, max_det_per_image = 40) #분할 이미지 크기\n",
    "\n",
    "        bench = create_model(\n",
    "            args.model,\n",
    "            bench_task='predict',\n",
    "            num_classes=args.num_classes,\n",
    "            pretrained=args.pretrained,\n",
    "            redundant_bias=args.redundant_bias,\n",
    "            soft_nms=args.soft_nms,\n",
    "            checkpoint_path=args.checkpoint,\n",
    "            checkpoint_ema=args.use_ema,\n",
    "            **extra_args,\n",
    "        )\n",
    "    model_config = bench.config\n",
    "\n",
    "    param_count = sum([m.numel() for m in bench.parameters()])\n",
    "    print('Model %s created, param count: %d' % (args.model, param_count))\n",
    "\n",
    "    bench = bench.cuda()\n",
    "\n",
    "    amp_autocast = suppress\n",
    "    if args.apex_amp:\n",
    "        bench = amp.initialize(bench, opt_level='O1')\n",
    "        print('Using NVIDIA APEX AMP. Validating in mixed precision.')\n",
    "    elif args.native_amp:\n",
    "        amp_autocast = torch.cuda.amp.autocast\n",
    "        print('Using native Torch AMP. Validating in mixed precision.')\n",
    "    else:\n",
    "        print('AMP not enabled. Validating in float32.')\n",
    "\n",
    "    #''' custom module test\n",
    "    if args.num_gpu > 1:\n",
    "        bench = torch.nn.DataParallel(bench, device_ids=list(range(args.num_gpu)))\n",
    "    #'''\n",
    "\n",
    "    #print('@@debug@@: ',args.dataset,args.root,args.split) # 디버그 : split_coco, data/split, val\n",
    "\n",
    "    dataset = create_dataset(args.dataset, args.root, args.split)\n",
    "    input_config = resolve_input_config(args, model_config)\n",
    "    loader = create_loader(\n",
    "        dataset,\n",
    "        input_size=input_config['input_size'],\n",
    "        batch_size=args.batch_size,\n",
    "        use_prefetcher=args.prefetcher,\n",
    "        interpolation=input_config['interpolation'],\n",
    "        fill_color=input_config['fill_color'],\n",
    "        mean=input_config['mean'],\n",
    "        std=input_config['std'],\n",
    "        num_workers=args.workers,\n",
    "        pin_mem=args.pin_mem)\n",
    "    # loader 출력해서 상태살피기\n",
    "    # 가장 쉬운 방법은 loader를 4개만들어서 출력**\n",
    "\n",
    "    evaluator = create_evaluator(args.dataset, dataset, pred_yxyx=False) # evaluator.py\n",
    "    \n",
    "    \n",
    "    bench.eval()\n",
    "    batch_time = AverageMeter()\n",
    "    end = time.time()\n",
    "    last_idx = len(loader) - 1\n",
    "\n",
    "    detect_time = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(loader):\n",
    "\n",
    "            time1 = time.time()\n",
    "\n",
    "            with amp_autocast():\n",
    "            \n",
    "                output = bench(input, img_info=target)\n",
    "            time2 =time.time()\n",
    "            \n",
    "            #print(target)\n",
    "            evaluator.add_predictions(output, target)\n",
    "\n",
    "            # measure elapsed time  \n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            \n",
    "            #visualization(output[0],int(target['file_name'][0].cpu()))\n",
    "\n",
    "            if i % args.log_freq == 0 or i == last_idx:\n",
    "                print(\n",
    "                    'Test: [{0:>4d}/{1}]  '\n",
    "                    'Time: {batch_time.val:.3f}s ({batch_time.avg:.3f}s, {rate_avg:>7.2f}/s)  '\n",
    "                    .format(\n",
    "                        i, len(loader), batch_time=batch_time,\n",
    "                        rate_avg=input.size(0) / batch_time.avg)\n",
    "                )\n",
    "            detect_time.append(time2-time1)\n",
    "            if i==2:\n",
    "              break\n",
    "    print('@@@@@@@@@@@@@@@')\n",
    "    print('탐지', np.mean(detect_time[1:]))\n",
    "    print('@@@@@@@@@@@@@@@')\n",
    "    mean_ap = 0.\n",
    "    if dataset.parser.has_labels:\n",
    "        mean_ap = evaluator.evaluate(output_result_file=args.results)\n",
    "    else:\n",
    "        evaluator.save(args.results)\n",
    "\n",
    "    return mean_ap\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model tf_efficientdet_d7 created, param count: 51871782\n",
      "AMP not enabled. Validating in float32.\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Test: [   0/103]  Time: 2.717s (2.717s,    0.37/s)  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The following classes have no ground truth examples: [1 2 3 4]\n",
      "Metrics:\n",
      "PascalBoxes_Precision/mAP@0.5IOU: 0.03985507246376811\n",
      "PascalBoxes_PerformanceByCategory/AP@0.5IOU/airplane: 0.03985507246376811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@@@@@@@@@@@\n",
      "탐지 1.0444177389144897\n",
      "@@@@@@@@@@@@@@@\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03985507246376811"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args_str = 'data_air --dataset air --model tf_efficientdet_d7 --num-gpu 4 --batch-size 1'\n",
    "#args_str = 'data --model tf_efficientdet_d0 --num-gpu 4'\n",
    "args,_ = parser.parse_known_args(args=args_str.split())\n",
    "validate(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('t': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "1609c5d6daf415add5fd1f90da23d5406f9079b60a4e5640100862a3157a35d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
